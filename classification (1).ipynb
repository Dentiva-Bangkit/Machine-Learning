{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pUObVrvw3Fwd",
        "outputId": "3f7c4526-9b0e-4068-92dd-ed34dbc67a8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ieV9z0M06Oz_"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "from PIL import Image\n",
        "import shutil\n",
        "from shutil import copyfile\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from PIL import Image\n",
        "from scipy import ceil\n",
        "import scipy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pKirh4DG6qWk",
        "outputId": "d28962b7-6a62-4b56-ab6d-4a5352362d5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Convert Successful\n",
            "Converted image = 0\n",
            "There are 1306 images of Calculus.\n",
            "\n",
            "Convert Successful\n",
            "Converted image = 0\n",
            "There are 2382 images of Data caries.\n",
            "\n",
            "Convert Successful\n",
            "Converted image = 0\n",
            "There are 183 images of Tooth Discoloration.\n",
            "\n",
            "Convert Successful\n",
            "Converted image = 0\n",
            "There are 1251 images of hypodontia.\n",
            "\n",
            "Convert Successful\n",
            "Converted image = 0\n",
            "There are 82 images of normal.\n",
            "\n",
            "Convert Successful\n",
            "Converted image = 0\n",
            "There are 2541 images of Mouth Ulcer.\n",
            "\n",
            "Convert Successful\n",
            "Converted image = 0\n",
            "There are 2349 images of Gingivitis.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "source_path = '/content/drive/MyDrive/Data'\n",
        "\n",
        "\n",
        "list=[]\n",
        "\n",
        "for i in os.listdir(source_path):\n",
        "    source_path_item = os.path.join(source_path, i)\n",
        "    n = 0\n",
        "    for j in os.listdir(source_path_item):\n",
        "        if j[-3:] == \"jpg\" or j[-3:] == \"gif\":\n",
        "            im = Image.open(os.path.join(source_path_item, j)).convert(\"RGB\")\n",
        "            im.save(os.path.join(source_path_item, j[:-3]+'jpeg'))\n",
        "\n",
        "            os.remove(os.path.join(source_path_item, j))\n",
        "            n += 1\n",
        "\n",
        "    print(\"Convert Successful\")\n",
        "    print(\"Converted image =\",n)\n",
        "    print(f\"There are {len(os.listdir(source_path_item))} images of\", i + \".\\n\")\n",
        "    list.append(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7V6EH7Lv6y9p"
      },
      "outputs": [],
      "source": [
        "root_dir = './temp'\n",
        "\n",
        "if os.path.exists(root_dir):\n",
        "    shutil.rmtree(root_dir)\n",
        "\n",
        "for i in list:\n",
        "    os.makedirs(os.path.join(root_dir,\"train\",i))\n",
        "    os.makedirs(os.path.join(root_dir,\"validation\",i))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tvMeCy9c61yO"
      },
      "outputs": [],
      "source": [
        "def split_data(SOURCE_DIR, TRAINING_DIR, VALIDATION_DIR, SPLIT_SIZE):\n",
        "\n",
        "  random_sample=random.sample(os.listdir(SOURCE_DIR),len(os.listdir(SOURCE_DIR)))\n",
        "\n",
        "  size=int(len(random_sample)*SPLIT_SIZE)\n",
        "\n",
        "  target=TRAINING_DIR\n",
        "  i=0\n",
        "\n",
        "  for item in random_sample:\n",
        "\n",
        "    item_source = os.path.join(SOURCE_DIR, item)\n",
        "\n",
        "    if os.path.getsize(item_source) == 0:\n",
        "      print(f'{item} is zero length, so ignoring.')\n",
        "    else:\n",
        "      copyfile(item_source, os.path.join(target, item))\n",
        "      i += 1\n",
        "\n",
        "    if i == size:\n",
        "      target = VALIDATION_DIR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8p-7bwLm7kDJ",
        "outputId": "9d99e86c-b859-4244-d7a8-d52e984eb26f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Split Calculus Successful\n",
            "There are 1044 images of Calculus for training.\n",
            "There are 262 images of Calculus for validation.\n",
            "\n",
            "Split Data caries Successful\n",
            "There are 1905 images of Data caries for training.\n",
            "There are 477 images of Data caries for validation.\n",
            "\n",
            "Split Tooth Discoloration Successful\n",
            "There are 146 images of Tooth Discoloration for training.\n",
            "There are 37 images of Tooth Discoloration for validation.\n",
            "\n",
            "Split hypodontia Successful\n",
            "There are 1000 images of hypodontia for training.\n",
            "There are 251 images of hypodontia for validation.\n",
            "\n",
            "Split normal Successful\n",
            "There are 65 images of normal for training.\n",
            "There are 17 images of normal for validation.\n",
            "\n",
            "Split Mouth Ulcer Successful\n",
            "There are 2032 images of Mouth Ulcer for training.\n",
            "There are 509 images of Mouth Ulcer for validation.\n",
            "\n",
            "Split Gingivitis Successful\n",
            "There are 1879 images of Gingivitis for training.\n",
            "There are 470 images of Gingivitis for validation.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "train_dir = os.path.join(root_dir,\"train\")\n",
        "val_dir = os.path.join(root_dir,\"validation\")\n",
        "\n",
        "for i in os.listdir(train_dir):\n",
        "  path = os.path.join(train_dir,i)\n",
        "  if len(os.listdir(path))>0:\n",
        "    for file in os.scandir(path):\n",
        "      os.remove(file.path)\n",
        "\n",
        "for i in os.listdir(val_dir):\n",
        "  path = os.path.join(val_dir,i)\n",
        "  if len(os.listdir(path))>0:\n",
        "    for file in os.scandir(path):\n",
        "      os.remove(file.path)\n",
        "\n",
        "split_size = .8\n",
        "\n",
        "for i in list:\n",
        "  split_data(os.path.join(source_path,i), os.path.join(train_dir, i), os.path.join(val_dir, i), split_size)\n",
        "  print(\"Split\", i, \"Successful\")\n",
        "  print(f\"There are {len(os.listdir(os.path.join(train_dir,i)))} images of\", i + \" for training.\")\n",
        "  print(f\"There are {len(os.listdir(os.path.join(val_dir,i)))} images of\", i + \" for validation.\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mVPE0YVPAL7R",
        "outputId": "d7499067-7e17-4d94-c4f4-df6f0fb59ca8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "NUM_CLASSES = len(os.listdir(source_path))\n",
        "\n",
        "BATCH_SIZE = 60\n",
        "\n",
        "base_model = tf.keras.applications.VGG16(input_shape=(225,225,3),\n",
        "                                         include_top=False,\n",
        "                                         weights='imagenet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VpS8cDzlARVo",
        "outputId": "84317752-a111-41e6-b413-915529366c57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 225, 225, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 225, 225, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 225, 225, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14714688 (56.13 MB)\n",
            "Trainable params: 14714688 (56.13 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "base_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tSzrqcJtAVEO"
      },
      "outputs": [],
      "source": [
        "last_desired_layer = base_model.get_layer(\"block5_pool\")\n",
        "\n",
        "last_output = last_desired_layer.output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pbuRztj5AY9_"
      },
      "outputs": [],
      "source": [
        "for layer in base_model.layers:\n",
        " layer.trainable = False\n",
        "x = tf.keras.layers.Flatten()(last_output)\n",
        "x = tf.keras.layers.Dense(256, activation = 'relu')(x)\n",
        "x = tf.keras.layers.Dense(128, activation = 'relu')(x)\n",
        "x = tf.keras.layers.Dense(64, activation = 'relu')(x)\n",
        "x = tf.keras.layers.Dense(32, activation = 'relu')(x)\n",
        "x = tf.keras.layers.Dense(NUM_CLASSES, activation = 'softmax')(x)\n",
        "\n",
        "model = tf.keras.models.Model(inputs = base_model.input, outputs = x)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3Z2yzwcAc84",
        "outputId": "f956c64e-7379-4962-c915-2f1697a8a50f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 225, 225, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 225, 225, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 225, 225, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 25088)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               6422784   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 7)                 231       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 21180935 (80.80 MB)\n",
            "Trainable params: 6466247 (24.67 MB)\n",
            "Non-trainable params: 14714688 (56.13 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jVXtc33KAgVK",
        "outputId": "f734eb6f-4a7e-4724-fb8e-f8dd1e6784fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 8071 images belonging to 7 classes.\n",
            "Found 2023 images belonging to 7 classes.\n",
            "Epoch 1/25\n",
            "135/135 [==============================] - 93s 602ms/step - loss: 2.1782 - accuracy: 0.2710 - val_loss: 1.6096 - val_accuracy: 0.2684\n",
            "Epoch 2/25\n",
            "135/135 [==============================] - 84s 621ms/step - loss: 1.3310 - accuracy: 0.4556 - val_loss: 1.4169 - val_accuracy: 0.2647\n",
            "Epoch 3/25\n",
            "135/135 [==============================] - 77s 571ms/step - loss: 1.3076 - accuracy: 0.4083 - val_loss: 1.3002 - val_accuracy: 0.2969\n",
            "Epoch 4/25\n",
            "135/135 [==============================] - 83s 615ms/step - loss: 1.1762 - accuracy: 0.4819 - val_loss: 1.0859 - val_accuracy: 0.6241\n",
            "Epoch 5/25\n",
            "135/135 [==============================] - 78s 576ms/step - loss: 1.1750 - accuracy: 0.4815 - val_loss: 1.2513 - val_accuracy: 0.4274\n",
            "Epoch 6/25\n",
            "135/135 [==============================] - 80s 591ms/step - loss: 1.2489 - accuracy: 0.4794 - val_loss: 1.1306 - val_accuracy: 0.4982\n",
            "Epoch 7/25\n",
            "135/135 [==============================] - 81s 603ms/step - loss: 1.2628 - accuracy: 0.4521 - val_loss: 1.2631 - val_accuracy: 0.3575\n",
            "Epoch 8/25\n",
            "135/135 [==============================] - 82s 604ms/step - loss: 1.1283 - accuracy: 0.5056 - val_loss: 1.1544 - val_accuracy: 0.4256\n",
            "Epoch 9/25\n",
            "135/135 [==============================] - 83s 614ms/step - loss: 1.0300 - accuracy: 0.5793 - val_loss: 1.0576 - val_accuracy: 0.4724\n",
            "Epoch 10/25\n",
            "135/135 [==============================] - 81s 601ms/step - loss: 1.0178 - accuracy: 0.5664 - val_loss: 1.2345 - val_accuracy: 0.3621\n",
            "Epoch 11/25\n",
            "135/135 [==============================] - 81s 599ms/step - loss: 1.0434 - accuracy: 0.5725 - val_loss: 1.1619 - val_accuracy: 0.4403\n",
            "Epoch 12/25\n",
            "135/135 [==============================] - 81s 599ms/step - loss: 1.0088 - accuracy: 0.5711 - val_loss: 0.9193 - val_accuracy: 0.6011\n",
            "Epoch 13/25\n",
            "135/135 [==============================] - 81s 602ms/step - loss: 1.0329 - accuracy: 0.5583 - val_loss: 1.0444 - val_accuracy: 0.5588\n",
            "Epoch 14/25\n",
            "135/135 [==============================] - 82s 609ms/step - loss: 0.9562 - accuracy: 0.6164 - val_loss: 0.8247 - val_accuracy: 0.6737\n",
            "Epoch 15/25\n",
            "135/135 [==============================] - 81s 600ms/step - loss: 0.9095 - accuracy: 0.6375 - val_loss: 0.9032 - val_accuracy: 0.5772\n",
            "Epoch 16/25\n",
            "135/135 [==============================] - 81s 603ms/step - loss: 0.8755 - accuracy: 0.6472 - val_loss: 1.0301 - val_accuracy: 0.5276\n",
            "Epoch 17/25\n",
            "135/135 [==============================] - 77s 570ms/step - loss: 0.8572 - accuracy: 0.6692 - val_loss: 0.9120 - val_accuracy: 0.5864\n",
            "Epoch 18/25\n",
            "135/135 [==============================] - 79s 588ms/step - loss: 0.8992 - accuracy: 0.6380 - val_loss: 0.8761 - val_accuracy: 0.6397\n",
            "Epoch 19/25\n",
            "135/135 [==============================] - 77s 573ms/step - loss: 0.8327 - accuracy: 0.6574 - val_loss: 0.8995 - val_accuracy: 0.6581\n",
            "Epoch 20/25\n",
            "135/135 [==============================] - 78s 579ms/step - loss: 0.8345 - accuracy: 0.6495 - val_loss: 0.7491 - val_accuracy: 0.6618\n",
            "Epoch 21/25\n",
            "135/135 [==============================] - 76s 566ms/step - loss: 0.8071 - accuracy: 0.6896 - val_loss: 0.9047 - val_accuracy: 0.5938\n",
            "Epoch 22/25\n",
            "135/135 [==============================] - 79s 588ms/step - loss: 0.8302 - accuracy: 0.6757 - val_loss: 1.1471 - val_accuracy: 0.4678\n",
            "Epoch 23/25\n",
            "135/135 [==============================] - 82s 606ms/step - loss: 0.8905 - accuracy: 0.6414 - val_loss: 1.0098 - val_accuracy: 0.5285\n",
            "Epoch 24/25\n",
            "135/135 [==============================] - 81s 602ms/step - loss: 0.8576 - accuracy: 0.6701 - val_loss: 0.9751 - val_accuracy: 0.5515\n",
            "Epoch 25/25\n",
            "135/135 [==============================] - 78s 577ms/step - loss: 0.7386 - accuracy: 0.7002 - val_loss: 0.9607 - val_accuracy: 0.5680\n",
            "Training Completed!\n"
          ]
        }
      ],
      "source": [
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1.0/255,\n",
        "                                     rotation_range=20,\n",
        "                                     width_shift_range=0.2,\n",
        "                                     height_shift_range=0.2,\n",
        "                                     horizontal_flip=True,\n",
        "                                     fill_mode='nearest')\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(directory=train_dir,\n",
        "                                                    target_size=(225,225),\n",
        "                                                    shuffle=False,\n",
        "                                                    class_mode='categorical')\n",
        "\n",
        "validation_datagen = ImageDataGenerator(rescale=1.0/255,\n",
        "                                     rotation_range=20,\n",
        "                                     width_shift_range=0.2,\n",
        "                                     height_shift_range=0.2,\n",
        "                                     horizontal_flip=True,\n",
        "                                     fill_mode='nearest')\n",
        "validation_generator = validation_datagen.flow_from_directory(directory=val_dir,\n",
        "                                                              target_size=(225,225),\n",
        "                                                              shuffle=False,\n",
        "                                                              class_mode='categorical')\n",
        "\n",
        "training_steps_per_epoch = np.ceil(train_generator.samples / BATCH_SIZE)\n",
        "validation_steps_per_epoch = np.ceil(validation_generator.samples / BATCH_SIZE)\n",
        "\n",
        "history = model.fit(train_generator,\n",
        "                    steps_per_epoch = training_steps_per_epoch,\n",
        "                    validation_data=validation_generator,\n",
        "                    validation_steps=validation_steps_per_epoch,\n",
        "                    epochs=25,\n",
        "                    verbose=1)\n",
        "\n",
        "print('Training Completed!')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}